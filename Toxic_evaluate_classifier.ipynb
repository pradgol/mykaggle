{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fire\n",
    "from fastai.text import *\n",
    "from fastai.lm_rnn import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CLAS_PATH=Path('/scratch/ppachigo/3192771/fastai/data/imdb_clas/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Backward ##\n",
    "\n",
    "def eval_clas(dir_path, cuda_id, lm_id='', clas_id=None, bs=64, backwards=False,\n",
    "              bpe=False):\n",
    "    print(f'dir_path {dir_path}; cuda_id {cuda_id}; lm_id {lm_id}; '\n",
    "         f'clas_id {clas_id}; bs {bs}; backwards {backwards}; bpe {bpe}')\n",
    "    if not hasattr(torch._C, '_cuda_setDevice'):\n",
    "        print('CUDA not available. Setting device=-1.')\n",
    "        cuda_id = -1\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "\n",
    "    PRE = 'bwd_' if backwards else 'fwd_'\n",
    "    PRE = 'bpe_' + PRE if bpe else PRE\n",
    "    IDS = 'bpe' if bpe else 'ids'\n",
    "    dir_path = Path(dir_path)\n",
    "    lm_id = lm_id if lm_id == '' else f'{lm_id}'\n",
    "    clas_id = lm_id if clas_id is None else clas_id\n",
    "    clas_id = clas_id if clas_id == '' else f'{clas_id}'\n",
    "    final_clas_file = f'clas_2_bwd_new' ## change to backward class id when running backward\n",
    "    lm_file = f'lm1_enc_bwd'\n",
    "    lm_path = dir_path / 'models' / f'{lm_file}.h5'\n",
    "    assert lm_path.exists(), f'Error: {lm_path} does not exist.'\n",
    "\n",
    "    bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "\n",
    "    if backwards:\n",
    "        val_sent = np.load(CLAS_PATH / 'tmp' / f'val_{IDS}_bwd.npy')\n",
    "    else:\n",
    "        val_sent = np.load(CLAS_PATH / 'tmp' / f'val_{IDS}.npy')\n",
    "    val_lbls = np.load(CLAS_PATH / 'tmp' / 'val_labels.npy').flatten()\n",
    "    val_lbls = val_lbls.flatten()\n",
    "    val_lbls -= val_lbls.min()\n",
    "    c=int(val_lbls.max())+1\n",
    "\n",
    "    val_ds = TextDataset(val_sent, val_lbls)\n",
    "    val_samp = SortSampler(val_sent, key=lambda x: len(val_sent[x]))\n",
    "    val_lbls_sampled = val_lbls[list(val_samp)]\n",
    "    val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "    md = ModelData(dir_path, None, val_dl)\n",
    "                                                                                                                        10,1          11%\n",
    "\n",
    "    if bpe: vs=30002\n",
    "    else:\n",
    "        itos = pickle.load(open(f'/scratch/ppachigo/3192771/fastai/data/imdb_lm/tmp/itos.pkl', 'rb'))\n",
    "#        itos = pickle.load(open(dir_path / 'tmp' / 'itos.pkl', 'rb'))\n",
    "        vs = len(itos)\n",
    "\n",
    "    m = get_rnn_classifier(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "                layers=[em_sz*3, 50, c], drops=[0., 0.])\n",
    "    learn = RNN_Learner(md, TextModel(to_gpu(m)))\n",
    "    learn.load_encoder(lm_file)\n",
    "    learn.load(final_clas_file)\n",
    "    preds_bwd = pd.DataFrame(learn.predict())\n",
    "    preds_bwd.to_csv('preds_bwd.csv')\n",
    "    predictions = np.argmax(learn.predict(), axis=1)\n",
    "    acc = (val_lbls_sampled == predictions).mean()\n",
    "    print('Accuracy =', acc, 'Confusion Matrix =')\n",
    "    print(confusion_matrix(val_lbls_sampled, predictions))\n",
    "\n",
    "\n",
    "if __name__ == '__main__': fire.Fire(eval_clas)\n",
    "\n",
    "\n",
    "                                                                                                                        68,0-1        Bot\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_clas(dir_path, cuda_id, lm_id='', clas_id=None, bs=64, backwards=False,\n",
    "              bpe=False):\n",
    "    print(f'dir_path {dir_path}; cuda_id {cuda_id}; lm_id {lm_id}; '\n",
    "         f'clas_id {clas_id}; bs {bs}; backwards {backwards}; bpe {bpe}')\n",
    "    if not hasattr(torch._C, '_cuda_setDevice'):\n",
    "        print('CUDA not available. Setting device=-1.')\n",
    "        cuda_id = -1\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "\n",
    "    PRE = 'bwd_' if backwards else 'fwd_'\n",
    "    PRE = 'bpe_' + PRE if bpe else PRE\n",
    "    IDS = 'bpe' if bpe else 'ids'\n",
    "    dir_path = Path(dir_path)\n",
    "    lm_id = lm_id if lm_id == '' else f'{lm_id}'\n",
    "    clas_id = lm_id if clas_id is None else clas_id\n",
    "    clas_id = clas_id if clas_id == '' else f'{clas_id}'\n",
    "    final_clas_file = f'clas_2' ## change to backward class id when running backward\n",
    "    lm_file = f'lm1_enc'\n",
    "    lm_path = dir_path / 'models' / f'{lm_file}.h5'\n",
    "    assert lm_path.exists(), f'Error: {lm_path} does not exist.'\n",
    "\n",
    "    bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "\n",
    "    if backwards:\n",
    "        val_sent = np.load(CLAS_PATH / 'tmp' / f'val_{IDS}_bwd.npy')\n",
    "    else:\n",
    "        val_sent = np.load(CLAS_PATH / 'tmp' / f'val_{IDS}.npy')\n",
    "    val_lbls = np.load(CLAS_PATH / 'tmp' / 'val_labels.npy').flatten()\n",
    "    val_lbls = val_lbls.flatten()\n",
    "    val_lbls -= val_lbls.min()\n",
    "    c=int(val_lbls.max())+1\n",
    "\n",
    "    val_ds = TextDataset(val_sent, val_lbls)\n",
    "    val_samp = SortSampler(val_sent, key=lambda x: len(val_sent[x]))\n",
    "    val_lbls_sampled = val_lbls[list(val_samp)]\n",
    "    val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "    md = ModelData(dir_path, None, val_dl)\n",
    "\n",
    "    if bpe: vs=30002\n",
    "    else:\n",
    "        itos = pickle.load(open(f'/scratch/ppachigo/3192771/fastai/data/toxic_lm/tmp/itos.pkl', 'rb'))\n",
    "#        itos = pickle.load(open(dir_path / 'tmp' / 'itos.pkl', 'rb'))\n",
    "        vs = len(itos)\n",
    "\n",
    "    m = get_rnn_classifier(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "                layers=[em_sz*3, 50, c], drops=[0., 0.])\n",
    "    learn = RNN_Learner(md, TextModel(to_gpu(m)))\n",
    "    learn.load_encoder(lm_file)\n",
    "    learn.load(final_clas_file)\n",
    "    preds_fwd = pd.DataFrame(learn.predict())\n",
    "    preds_fwd.to_csv('preds_fwd.csv')\n",
    "    predictions = np.argmax(learn.predict(), axis=1)\n",
    "    acc = (val_lbls_sampled == predictions).mean()\n",
    "    print('Accuracy =', acc, 'Confusion Matrix =')\n",
    "    print(confusion_matrix(val_lbls_sampled, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ensemble  ####\n",
    "\n",
    "    preds_bwd = pd.read_csv('preds_bwd.csv')\n",
    "    preds_fwd = pd.read_csv('preds_fwd.csv')\n",
    "\n",
    "    print(preds_bwd.head())\n",
    "    print(preds_fwd.head())\n",
    "\n",
    "    preds_bwd.drop(preds_bwd.columns[0],axis =1, inplace = True)\n",
    "    preds_fwd.drop(preds_fwd.columns[0],axis =1, inplace = True)\n",
    "\n",
    "    print(preds_bwd.head())\n",
    "    print(preds_fwd.head())\n",
    "\n",
    "\n",
    "    preds_ensemble = pd.DataFrame()\n",
    "\n",
    "    preds_ensemble['0'] = preds_bwd['0'] + preds_fwd['0']\n",
    "    preds_ensemble['1'] = preds_bwd['1'] + preds_fwd['1']\n",
    "\n",
    "    print(preds_ensemble.head())\n",
    "\n",
    "    preds_ensemble.to_csv('preds_ensemble2.csv')\n",
    "\n",
    "    preds_array = np.array(preds_ensemble)\n",
    "\n",
    "    predictions = np.argmax(preds_array,axis = 1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    predictions_df.to_csv('predictions2.csv')\n",
    "\n",
    "    acc_ens = (val_lbls_sampled == predictions).mean()\n",
    "    print('Accuracy_ens = ',acc_ens, 'Confusion Matrix = ')\n",
    "    print(confusion_matrix(val_lbls_sampled, predictions))\n",
    "\n",
    "if __name__ == '__main__': fire.Fire(eval_clas)\n",
    "\n",
    "                                                                                                                        104,0-1       98%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
